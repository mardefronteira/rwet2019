{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tracery\n",
      "  Downloading https://files.pythonhosted.org/packages/96/9a/7a7ffa8ace49ac6a3f422fdd83caf8d0ad0d132f01389f02845379033a7b/tracery-0.1.1.tar.gz\n",
      "Building wheels for collected packages: tracery\n",
      "  Running setup.py bdist_wheel for tracery ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/Mar/Library/Caches/pip/wheels/22/ba/09/8341e10777b9d2bf6d5414d3c9627b7812f5bedce4b3edacac\n",
      "Successfully built tracery\n",
      "Installing collected packages: tracery\n",
      "Successfully installed tracery-0.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tracery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracery\n",
    "from tracery.modifiers import base_english\n",
    "import json\n",
    "import random\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#path: adverbs['adverbs'][item]\n",
    "adverbs = json.loads(open(\"adverbs.json\").read())\n",
    "\n",
    "#path: infinitiveVerbs[item]\n",
    "infinitiveVerbs = json.loads(open(\"infinitive_verbs.json\").read())\n",
    "\n",
    "#path: nouns['nouns'][item]\n",
    "nouns = json.loads(open(\"nouns.json\").read())\n",
    "\n",
    "#path: personalNouns['personalNouns'][item]\n",
    "personalNouns = json.loads(open(\"personal_nouns.json\").read())\n",
    "\n",
    "#path: prepositions['prepositions'][item]\n",
    "prepositions = json.loads(open(\"prepositions.json\").read())\n",
    "\n",
    "#path: adjectives['adjs'][item]\n",
    "adjectives = json.loads(open(\"adjs.json\").read())\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fins'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules = {\n",
    "    \"origin\":[\"nice #origin.a#\", \"#end.s#\"],\n",
    "    \"end\": \"fin\"\n",
    "}\n",
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "grammar.flatten(\"#origin#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Repetition blocks;\n",
    "• Flow blocks;\n",
    "• Single word or phrase blocks;\n",
    "• Spaces;\n",
    "• Imagetic phrases rather than rational thoughts;\n",
    "• Graphic modifications to single words (uppercases, space between letters);\n",
    "• Neologisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          naturally     \n",
      "Pernicious stretch save regulators rejoice along moo scarcely drums. An outpost valiant memorises. Lineages dislike, lightest intersection despite a southern marches. A haggler spots according to standpoints disapprove. A ma'am portmanteau concerns, laughable doorstep about grateful inevitability, codings slip. The bullied xiphias interrupts, combat a collaborator sneezed. A battling sneezes. The sinking lightens, a nobody buries, incomprehensible technology except for a postponer examines, a pochard signals without a normalcy books throughout a consul sucks, a stewardess upwardly received. A wonders surprises. A retailer sparkles. A sermonizer fears, a meringue connects, abbeys please. The withholding stitches. A jar obediently mends as far as a scrum blots, skeleton a nightmare buzzed opposite of appraisals dream, a fascism bounces, vogues spray close to a precinct caresin front of hastily, \n",
      "in front of a clutches, \n",
      "in front of a pause cruelly, \n",
      "in front of not \n",
      "          sensed\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fixing           kangaroo.\n"
     ]
    }
   ],
   "source": [
    "rules = {\n",
    "    \"origin\": [\"#block##space#\\n#origin.capitalize#\\n\", \"#block##space#\\n#block##space#\\n#block#\"]\n",
    "    \n",
    "    ,\"block\": [\"[thisPrep:#prep#]#repetition#\",\"#air.capitalize##flow#\",\"#space##air#\"]\n",
    "    \n",
    "    ,\"repetition\": [\"#thisPrep# #repeat#, \\n#repetition#\",\"#thisPrep# #repeat# \\n#space##air#\\n#space#\"]\n",
    "    ,\"repeat\": [\"#noun.a#\", \"#pNoun.a#\", \"#adv#\", \"#adj.a# #noun#\", \"#verb.a# #adv#\"]\n",
    "    \n",
    "    ,\"flow\": [\". #noun.a.capitalize# #verb.s##flow#\", \". #noun.a.capitalize# #adj# #verb.s##flow#\", \n",
    "              \". #pNoun.a.capitalize# #verb.s##flow#\", \". #pNoun.a.capitalize# #adv# #verb.s##flow#\", \n",
    "              \". #noun.s.capitalize# #verb##flow#\",\n",
    "              \". The #noun# #verb.s##flow#\", \". The #adj# #noun# #verb.s##flow#\", \n",
    "              \". The #pNoun# #verb.s##flow#\", \". The #adj# #pNoun# #verb.s##flow#\", \n",
    "              \". #noun.s.capitalize# #verb##flow#\",\n",
    "              \", #noun.a# #verb.s##flow#\", \", #adj# #noun.a# #verb.ed##flow#\", \n",
    "              \", #pNoun.a# #verb.s##flow#\", \", #pNoun.a# #adv# #verb.ed##flow#\", \n",
    "              \", #noun.s# #verb##flow#\",\n",
    "              \" #prep# #noun.a# #verb.s##flow#\", \" #prep# #adj# #noun.a# #verb.s##flow#\", \n",
    "              \" #prep# #pNoun.a# #verb.s##flow#\", \" #prep# #pNoun# #adv# #verb.s##flow#\", \n",
    "              \" #prep# #noun.s# #verb##flow#\",\n",
    "              \" #prep# #adj# #noun##flow#\", \", #adj# #noun##flow#\", \". #adj.capitalize# #noun##flow#\"\n",
    "              \" #air#.\", \" #space##air#.\", \"[thisPrep:#prep#]#repetition#\"]\n",
    "    \n",
    "    ,\"air\": [\"#adj#\", \"#noun#\", \"#neo#\", \"#adv#\", \"#adj# #verb#\", \"#verb.ed# #adv#\"]\n",
    "    \n",
    "    ,\"space\": [\"          \",\"     \",\"\\n\",\"\\n\\n\",\"\\n\\n\\n\"]\n",
    "    \n",
    "    ,\"adv\": adverbs['adverbs']\n",
    "    ,\"verb\": infinitiveVerbs\n",
    "    ,\"noun\": nouns['nouns']\n",
    "    ,\"pNoun\": personalNouns['personalNouns']\n",
    "    ,\"prep\": prepositions['prepositions']\n",
    "    ,\"adj\": adjectives['adjs']\n",
    "    ,\"neo\": [\"#adj##noun#\",\"#pNoun##adv#\", \"#verb##adj#\", \"#adv##verb#\"]\n",
    "}\n",
    "\n",
    "\n",
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "print(grammar.flatten(\"#origin#\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
